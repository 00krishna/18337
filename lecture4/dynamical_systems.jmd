---
title: How Loops Work, An Introduction to Discrete Dynamics
author: Chris Rackauckas
date: September 8th, 2019
---

The basics of most scientific models are dynamical systems. In this lecture
we will go over the basic properties of dynamical systems and understand their
general behavior through code. We will also learn the idea of stability as
an asymtopic property of a mapping, and understand when a system is stable.

## Discrete Dynamical Systems

A discrete dynamical system is a system which updates through discrete updates:

$$u_{n+1} = model(u_n,n)$$

There are many examples of a discrete dynamical system found throughout the
scientific literature. For example, many ecological models are discrete dynamical
systems, with the most famous being the logistic map:

$$u_{n+1} = r u_n (1 - u_n)$$

describing the growth of a population with a carrying capacity of 1 and a growth
rate of `r`. Another way in which discrete dynamical systems are often encountered
is through time series models. These are generally seen in financial forecasting
and For example, the autoregressive model AR1 is
the following linear dynamical system:

$$u_{n+1} = \alpha u_n + \epsilon_n$$

where $\epsilon$ is a standard normal random number. The AR(k) model allows
itself to update using delays as well:

$$u_{n+1} = \sum_{j=0}^{k-1} \alpha_j u_{n-j} + \epsilon_n$$

The ARMA model is one that allows using delays on the randomness as well:

$$u_{n+1} = \sum_{j=0}^{k-1} (\alpha_j u_{n-j}  + \beta_j \epsilon_{n-j})$$

Another embodiment of a discrete dynamical system is a Recurrent Neural Network
(RNN). In its simplest form, a RNN is a system of the form:

$$u_{n+1} = u_n + f(u_n,\theta)$$

where $f$ is a neural network parameterized by $\theta$.

Note that discrete dyamical systems are even more fundamental than just the
ones shown. In any case where a continuous model is discretized to loop on the
computer, the resulting algorithm is a discrete dynamical system and thus
evolves according to its properties. This fact will be revisited later.

## Properties of Linear Dynamical Systems

First let's take a look at the scalar linear dynamical system:

$$u_{n+1} = \alpha u_{n}$$

We want to ask what the global or geometric behavior of this system is. We
can do this by expanding out the system. Notice that if ``u_0`` is known,
then

$$u_{n+1} = \alpha^n u_0$$

The global behavior can then be categorized as:

- If $\Vert \alpha \Vert < 1$, then $u_n \rightarrow 0$
- If $\Vert \alpha \Vert > 1$, then $u_n \rightarrow \infty$

If $\Vert \alpha \Vert = 1$, then $u_n \rightarrow u_0$ if everything is in the
real numbers, but more complex dynamics can occur on the complex plane.

## Nonlinear Geometric Dynamics

The Geometric Theory of Dynamical Systems is the investigation of their long-term
properties and the geometry of the phase space which they occupy. Let's start
looking at this in practical terms: how do nonlinear update equations act
as time goes to infinity?

#### Banach Fixed Point Theorem

There are surprisingly simple results that we can prove. First let's recall
the Banach Fixed Point Theorem (also known as the Contraction Mapping Theorem).
Let $(X,d)$ be a metric space ($X$ is the set of points we are thinking of, here
the real numbers. $d$ is a distance function). $f$ is a contraction mapping if

$$d(f(x),f(y)) \leq \alpha d(x,y)$$

where $\alpha < 1$, that is, if applying $f$ always decreases the distance.
The theorem then states
that if $f$ is a contraction mapping, then there is a unique fixed point
(point $x\ast$ where $f(x\ast)=x\ast$) and a sequence such that $x_0 \rightarrow x\ast$
where

$$x_{n+1} = f(x_n)$$

The proof is by induction, showing that the sequence is Cauchy. For some $m>n$
we do by the Triangle Inequality

$$d(x_m,x_n) \leq d(x_{m},x_{m-1}) + \ldots + d(x_{n+1},x_n)$$

then apply the contraction relation down to the bottom:

$$d(x_m,x_n) \leq q^{m-1} d(x_{1},x_{0}) + \ldots + q^{n} d(x_{1},x_0)$$

$$d(x_m,x_n) \leq q^n d(x_{1},x_{0}) \sum_{k=0}^{m-n-1} q^k$$

and since adding more never hurts:

$$d(x_m,x_n) \leq q^n d(x_{1},x_{0}) \sum_{k=0}^{\infty} q^k$$

But that summation is just a geometric series now, and since $q<1$ we know it
converges to $1/(1-q)$, and so we get:

$$d(x_m,x_n) \leq \frac{q^n}{1-q} d(x_{1},x_{0})$$

The coefficient converges to zero as $n$ increases, and so the sequence must
be Cauchy, which implies there's a unique fixed point.

#### Stability of Linear Discrete Dynamical Systems

Now let's take a mapping $f$ which is sufficiently nice ($f \in C^1$, i.e.
the derivative of $f$ exists and is continuous), where

$$x_{n+1} = f(x_n)$$

Assume that $\Vert f^\prime (x^\ast) \Vert < 1$ at some point where $f(x)=x$. Then by
continuity of the second derivative, it follows that there is a neighborhood
where $\Vert f^\prime (x) \Vert < 1$ (). Now recall that this means

$$df/dx \leq 1$$

which means that, for any $x$ and $y$ in the neighborhood,

$$\Vert \frac{f(y)-f(x)}{y-x} \Vert \leq 1$$

or

$$\Vert f(y)-f(x) \Vert \leq \Vert y-x \Vert$$

This is essentially another way of saying that a function that is differentiable
is Lipschitz, where we can use the derivative as the Lipschitz bound. But notice
this means that, in this neighborhood, a function with a derivative less than
1 is a contraction mapping, and thus there is a limiting sequence which goes to
the fixed point by the Banach Fixed Point Theorem. Furthermore, the uniquess
guerentees that there is only one fixed point in a sufficiently small neighborhood
where the derivative is all less than 1.

A way to interpret this result is that, any nice enough function $f$ is locally
linear. Thus we can understand the global properties of $f$ by looking the
linearization of its dynamics, where the best linear approximation is the
linear function $f^\prime (x) x$. This means that we can think of

$$x_{n+1} = f(x_n)$$

locally as being approximated by

$$x_{n+1} = f^\prime (x) x_n$$

and so if the derivative is less than 1 in some neighborhood of a fixed point,
then we locally have a linear dynamical system which looks like the simple
$x_{n+1} = \alpha x_n$ where $\alpha <1$, and so we get the same convergence
property.

This is termed "stability" since, if you are a little bit off from the fixed
point, you will tend to go right back to it. An unstable fixed point is one
where you fall away. And what happens when the derivative is one? There are
various forms of semi-stability that can be proved which go beyond the topic
of this course.

#### Update Form

Now let's look at another form:

$$x_{n+1} = x_n + f(x_n)$$

For example, this is what we generally see with the recurrent neural network
(or, as we will find out later, this is how discretizations of continuous systems
tend to look!). In this case, we can say that this is a dynamical system

$$x_{n+1} = g(x_n)$$

and so if $-2 < f^\prime < 0$, then $g^\prime = 1 + f^\prime < 0$ and so we have the
same stability idea except now with a condition shifted to zero instead of one.

## Multivariable Systems

Now let $x \in R^k$ be a vector, and define discrete mappings

$$x_{n+1} = f(x_n)$$

The linear system is

$$x_{n+1} = A x_n$$

The easiest way to analyze a multidimensional system is to turn it into a bunch
of single dimension systems. To do this, assume that $A$ is diagonal. This means
that there exists a diagonalization $A =P^{-1}DP$ where $P$ is the matrix of
eigenvectors and $D$ is the diagonal matrix of eigenvalues. We can then decompose
the system as follows:

$$Px_{n+1} = DPx_n$$

and now define new variables $z_n = Px_n$. In these variables,

$$z_{n+1} = D z_n$$

but $D$ is diagonal, so this is a system of $k$ independent linear dynamical
systems. We know that the linear dynamical system will converge to zero if
$\Vert D_i \Vert < 1$, and so this means that $z_n$ converges to zero if all
of the eigenvalues are within the unit circle. Since $P0 = 0$, this implies that
if all of the eigenvalues of $A$ are in the unit circle, then $x_n \rightarrow 0$.

A multidimensional version of the contraction mapping theorem is then proven
exactly in this manner, meaning that if $f(x) = 1$ and all eigenvalues of the
Jacobian matrix (the linearization of $f$) are in the unit circle, then $x$ is
a unique fixed point in some neighborhood.

#### Understanding Delayed Systems

A similar property holds in linear dynamical systems with delays. Take

$$x_{n+1} = \sum_{j=0}^{k-1} \alpha_j x_{n-j}$$

Notice that we can write this as a multidimensional non-delayed system. Let
$x_n^i$ be the $i$th term in the vector of the $n$ time. Then we have:

$$x_{n+1}^1 = \sum_{j=1}^{k-1} \alpha_{j-1} x_{n}^{j}$$

as an equivalent way to write this, where

$$x_{n+1}^j = x_n^{j-1}$$

for all of the other terms. Essentially, instead of a system with a delay, we
store the memory in other terms of the vector, and keep shifting them down.
However, this makes our system much easier to analyze. Instead of a linear
delayed dynamical system, this is now a linear multidimensional dynamical
system. Its characteristic polynomial is

$$\varphi(x) = 1 - \sum_{j=0}^{k-1} \alpha_j x^j$$

and so if all of the roots are in the unit circle then this system is stable.

#### Stochastic Dynamical Systems

Now let's take a look again at the autoregressive process from time series
analysis:

$$u_{n+1} = \sum_{j=0}^{k-1} \alpha_j u_{n-j} + \epsilon_n$$

In a very quick handwavy way, we can understand such a system by seeing how the
perturbations propogate. If $u_0 = 0$, then the starting is just $\epsilon_0$.
If we assume all other $\epsilon_i = 0$, then this system is the same as a linear
dynamical system with delays. If all of the roots are in the unit circle, then
it goes to zero, meaning the perturbation is forgotten or squashed over time.

We can analyze this more by using the moments. Notice that, by the linearity
of the expected value,

$$\mathbb{E}[u_{n+1}] = \sum_{j=0}^{k-1} \alpha_j \mathbb{E}[u_{n-j}]$$

is a deterministic linear dynamical system which converges if the roots are in
the unit circle. This means that the mean stabilizes over time if all of the
roots are in the unit circle. In time series analysis, this is called stationarity
of the time series.

We can then also look at the stability of the variance as well. Recall that

$$\mathbb{V}[x] = \mathbb{E}[x^2] - \mathbb{E}[x]^2$$

and so therefore

$$\mathbb{E}[u_{n+1}^2] = \mathbb{E}[\sum_{j=0}^{k-1} \alpha_j u_{n-j}^2]$$

and with a bunch of analysis here, working in the same way with the same basic
ideas, we can determine conditions on which the variance goes to zero.
